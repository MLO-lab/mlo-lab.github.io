<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects | MLO Lab</title><link>https://mlo-lab.github.io/project/</link><atom:link href="https://mlo-lab.github.io/project/index.xml" rel="self" type="application/rss+xml"/><description>Projects</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2026 MLO Lab</copyright><lastBuildDate>Wed, 24 Sep 2025 15:55:09 +0200</lastBuildDate><image><url>https://mlo-lab.github.io/media/logo_huedbb8239ffd36c55e33765ff7c80fb90_78702_300x300_fit_lanczos_2.png</url><title>Projects</title><link>https://mlo-lab.github.io/project/</link></image><item><title>Quantitative Imaging in Oncology</title><link>https://mlo-lab.github.io/project/medical-imaging/</link><pubDate>Wed, 24 Sep 2025 15:55:09 +0200</pubDate><guid>https://mlo-lab.github.io/project/medical-imaging/</guid><description>&lt;p>Quantitative imaging in oncology combines advanced microscopy, image analysis and machine learning to study cancer in unprecedented detail. By extracting rich spatial and molecular information from tissues, we aim to better understand how tumors grow, respond to treatments and interact with their surroundings. In our lab, we have developed colocatome frameworks to map and quantify in situ cellular organization, revealing how microenvironments regulate cell behavior. In parallel, we extract reproducible radiomic features such as texture, intensity and shape, together with quantitative MRI metrics like relaxation times, and apply interpretable machine-learning models to link these imaging biomarkers to clinical outcomes. This enables precise tumor localization and non-invasive monitoring of disease progression.&lt;/p>
&lt;h3 id="quantitative-imaging-and-spatial-analysis">Quantitative Imaging and Spatial Analysis&lt;/h3>
&lt;p>Our work focuses on developing computational frameworks to analyze high-resolution multiplex microscopy images of tissues such as bone marrow, generated by &lt;a href="https://www.kokkaliarislab.com/" target="_blank" rel="noopener">Quantitative Spatial Cancer Biology - Kokkaliaris lab&lt;/a>. We specialize in extracting spatial and morphological features from complex, multi-modal image data.&lt;/p>
&lt;p>We have developed a framework that enables the integration and analysis of multiple biological replicates with complementary information in a shared spatial reference space. Building on this, we established a pipeline to extract and quantify spatial remodeling of the cellular neighborhood during the aging process. These tools allow us to investigate how hematopoietic stem cells, blood vessels, megakaryocytes, adipocytes, and stromal components are spatially organized and how these patterns evolve with age or in response to treatment.&lt;/p>
&lt;p>&lt;img src="bone_marrow.avif" alt="Bone Marrow Tissue">&lt;/p>
&lt;h3 id="radiomics-and-quantitative-mri">Radiomics and Quantitative MRI&lt;/h3>
&lt;p>Our imaging research also includes radiological data analysis, with a focus on transitioning from qualitative interpretation to quantitative, reproducible metrics. In radiomics, we extract features such as texture, intensity, and shape from defined regions of interest within MRI scans, and use machine learning models to link these features to clinical outcomes. We emphasize interpretability and robustness, testing models on controlled environments to avoid confounding due to real-patient variability and ethical exposure limitations.&lt;/p>
&lt;p>In parallel, we employ quantitative MRI (qMRI) techniques to move beyond traditional contrast-based imaging. By measuring intrinsic physical properties of tissues, e.g. relaxation times, we obtain microstructural insights into tissue composition, particularly in brain imaging. Combining qMRI with machine learning enables precise localization of tumors and assessment of disease progression, further enhancing the clinical utility of radiological data.&lt;/p></description></item><item><title>Trustworthy Machine Learning in Biomedical Research</title><link>https://mlo-lab.github.io/project/trustworthy-ml/</link><pubDate>Tue, 10 Jun 2025 22:46:01 +0200</pubDate><guid>https://mlo-lab.github.io/project/trustworthy-ml/</guid><description>&lt;p>As machine learning becomes increasingly central to biomedical discovery and clinical decision-making, ensuring the reliability, fairness, and interpretability of these models is critical. In our lab, we are committed to developing and applying machine learning methods that are not only accurate but also &lt;strong>trustworthy&lt;/strong>, meaning they are robust to noise, generalizable across datasets, transparent in their decision-making, and aligned with ethical and clinical standards.&lt;/p>
&lt;p>Our work spans multiple aspects of trustworthy ML, including uncertainty quantification, model calibration, interpretability, fairness in predictive models, and robustness to distributional shifts. These components are especially important in healthcare, where decisions influenced by models can have direct consequences for patients.&lt;/p>
&lt;p>In the context of multi-omics data, single-cell analysis, and quantitative imaging, we embed trustworthiness principles throughout the model development pipeline, from data preprocessing and integration to prediction and interpretation. This ensures that our computational outputs can be confidently used to guide biological insight and translational applications.&lt;/p>
&lt;h3 id="model-calibration-under-distribution-shift">Model Calibration Under Distribution Shift&lt;/h3>
&lt;p>Current-generation neural networks exhibit systematic underconfidence rather than the overconfidence reported in earlier models, and demonstrate improved calibration robustness under distribution shift. However, post-hoc calibration methods become less effective or even detrimental under severe shifts. Our analysis across ImageNet and biomedical datasets reveals that calibration insights from web-scraped benchmarks have limited transferability to specialized domains, where convolutional architectures consistently outperform transformers regardless of model generation. This work challenges established calibration paradigms and emphasizes the need for domain-specific architectural evaluation beyond standard benchmarks.
&lt;img src="distribution_shift_post-hoc.png" alt="Distribution Shift Calibration">&lt;/p>
&lt;p>[&lt;a href="https://arxiv.org/abs/2506.09593" target="_blank" rel="noopener">pdf&lt;/a>, &lt;a href="https://github.com/MLO-lab/ModelTransformer" target="_blank" rel="noopener">repo&lt;/a>]&lt;/p>
&lt;h3 id="uncertainty-quantification-for-classification-and-applications">Uncertainty Quantification for Classification and Applications&lt;/h3>
&lt;p>Reliably estimating the uncertainty of a prediction throughout the model lifecycle is crucial in many safety-critical applications. Since ML-based decision models are increasingly deployed in dynamic environments, understanding when and why a model might fail becomes as important as achieving accurate predictive performance. In our group, we focus on developing theoretically sounded methods for uncertainty quantification that remain robust across different applications, enabling more trustworthy and transparent AI systems.
&lt;img src="BI_plot.png" alt="BI">&lt;/p>
&lt;h4 id="uncertainty-estimates-of-predictions-via-a-general-bias-variance-decomposition-aistats-2023">Uncertainty Estimates of Predictions via a General Bias-Variance Decomposition (AISTATS 2023)&lt;/h4>
&lt;p>Proper scoring rules (e.g., Brier score or negative log-likelihood) are commonly used as loss functions in machine learning, as they are designed to assign optimal predictions to the target distribution. However, it remains unclear how to decompose these scores in a way that a component capturing the model’s predictive uncertainty arises. To address this, we derive a general bias-variance decomposition for proper scoring rules, where the Bregman Information (BI) naturally emerges as the variance term. This new theoretical insight has practical implications for classification tasks: since the decomposition applies to the cross-entropy loss, it allows us to quantify predictive uncertainty directly in the logit space (the standard output of neural networks) without requiring a normalisation step. Extensive empirical results demonstrate the effectiveness and robustness of this method, particularly in out-of-distribution settings. [&lt;a href="https://proceedings.mlr.press/v206/gruber23a/gruber23a.pdf" target="_blank" rel="noopener">pdf&lt;/a>, &lt;a href="https://github.com/MLO-lab/Uncertainty_Estimates_via_BVD" target="_blank" rel="noopener">repo&lt;/a>]&lt;/p>
&lt;h4 id="how-to-leverage-predictive-uncertainty-estimates-for-reducing-catastrophic-forgetting-in-online-continual-learning-tmlr-2025">How to Leverage Predictive Uncertainty Estimates for Reducing Catastrophic Forgetting in Online Continual Learning (TMLR 2025)&lt;/h4>
&lt;p>In many real-world scenarios, we want models to continuously learn new information without forgetting what they already know. In memory-based online continual learning, a key challenge is managing a limited memory buffer to mitigate catastrophic forgetting (CF) — but what is the best strategy for selecting samples to store in the memory? Under an uncertainty lens, we investigate what characteristics make samples effective in alleviating CF. Starting from the examination of the properties and behaviours of popular uncertainty estimates, we identify that they mostly capture the irreducible aleatoric uncertainty and hypothesise that a better strategy should focus on the epistemic uncertainty instead. To this end, we propose using Bregman Information – derived from our general bias-variance decomposition of strictly proper scores – as an effective estimator of epistemic uncertainty, leading to improved memory population strategy and reduced forgetting. [&lt;a href="https://openreview.net/pdf?id=dczXe0S1oL" target="_blank" rel="noopener">pdf&lt;/a>, &lt;a href="https://github.com/MLO-lab/uncertainty_estimates_for_CF" target="_blank" rel="noopener">repo&lt;/a>]&lt;/p>
&lt;h4 id="federated-continual-learning-goes-online-uncertainty-aware-memory-management-for-vision-tasks-and-beyond--iclr-2025">Federated Continual Learning Goes Online: Uncertainty-Aware Memory Management for Vision Tasks and Beyond (ICLR 2025)&lt;/h4>
&lt;p>Federated Continual Learning (FCL) is a powerful paradigm that combines the privacy-preserving benefits of Federated Learning (FL) with the ability to learn sequentially over time, as in Continual Learning (CL). However, catastrophic forgetting still remains a major challenge. Most existing FCL methods rely on generative models, assuming an offline setting where all task data are available beforehand. But in real-world applications, data often arrives sequentially in small chunks — a challenge that remains largely unaddressed. To address this, we introduce a novel framework for online federated continual learning. To address scenarios where storing the full dataset locally is impractical, we propose an effective memory-based baseline that integrates uncertainty-aware updates — based on Bregman Information — with random replay to reduce catastrophic forgetting. Unlike generative approaches, our uncertainty-based solution is simple to implement and adaptable across different data modalities. [&lt;a href="https://openreview.net/pdf?id=f65RuQgVlp" target="_blank" rel="noopener">pdf&lt;/a>, &lt;a href="https://github.com/MLO-lab/online-FCL" target="_blank" rel="noopener">repo&lt;/a>]&lt;/p>
&lt;h3 id="uncertainty-quantification-for-generative-ai">Uncertainty Quantification for Generative AI&lt;/h3>
&lt;p>Generative AI models in general and large language models in particular have emerged as a disruptive technology that has been rapidly democratized. Their use in critical domains such as medicine, scientific research, and politics has raised serious concerns about reliability. Consequently, robust estimation of their uncertainty is essential to build trust and to prevent the potentially severe consequences of failures. We develop methods to quantify and calibrate their uncertainty across different modalities, while accounting for the specific characteristics of each modality.
&lt;img src="UQ_LLM_plot.png" alt="UQ_LLM">&lt;/p>
&lt;h4 id="a-bias-variance-covariance-decomposition-of-kernel-scores-for-generative-models-icml-2024">A Bias-Variance-Covariance Decomposition of Kernel Scores for Generative Models (ICML 2024)&lt;/h4>
&lt;p>This paper tackles a core gap in generative AI: there’s no unified, theory-grounded way to assess generalization and uncertainty across modalities or closed-source models. We introduce the first bias–variance–covariance decomposition for kernel scores, yielding kernel-based measures that can be estimated directly from generated samples, without access to the underlying model. Because kernels work from samples alone and are computed based on vector representations of these samples, the framework applies uniformly to images, audio, and language. In experiments, the approach explains generalization behavior (including mode collapse patterns) and delivers stronger uncertainty signals, even for closed-source LLMs.&lt;/p>
&lt;p>[&lt;a href="https://proceedings.mlr.press/v235/gruber24a.html" target="_blank" rel="noopener">pdf&lt;/a>, &lt;a href="https://github.com/MLO-lab/BVCD_generative_models" target="_blank" rel="noopener">repo&lt;/a>]&lt;/p></description></item><item><title>Computational Molecular Medicine</title><link>https://mlo-lab.github.io/project/comp-medicine/</link><pubDate>Tue, 10 Jun 2025 22:36:09 +0200</pubDate><guid>https://mlo-lab.github.io/project/comp-medicine/</guid><description>&lt;p>Single-cell multi-omics data offer powerful opportunities to study disease at unprecedented resolution, but they also present significant challenges. The data are often sparse, noisy, and extremely high-dimensional, with technical differences between batches or donors that can obscure true biological signals. Our lab combines advanced computational methods with high-dimensional biological data to exludes technical artifacts and uncover mechanisms of disease progresssion and therapy response, with a particular emphasis on cancer and metabolic disorder.&lt;/p>
&lt;h3 id="single-cell-multi-omics-for-clinical-cohorts">Single-Cell Multi-Omics for Clinical Cohorts&lt;/h3>
&lt;p>We specialize in the analysis of clinical single-cell multi-omics datasets, particularly from cancer and metabolic disease cohorts. Using state-of-the-art machine learning techniques, we analyze single-cell RNA sequencing and chromatin accessibility data to characterize cellular heterogeneity and regulatory dynamics. Our pipeline includes robust dimensionality reduction, clustering, and batch correction methods, allowing us to identify distinct cell populations and states across individuals. Through probabilistic graphical modeling and motif enrichment analysis, we reconstruct gene regulatory networks that govern disease-specific transcriptional programs. These approaches allow us to overcome the sparsity and noise inherent to single-cell data and extract biologically meaningful patterns that inform prognosis and therapeutic strategy.&lt;/p>
&lt;h3 id="multi-omics-for-mouse-models-of-cancer-progression">Multi-Omics for Mouse Models of Cancer Progression&lt;/h3>
&lt;p>To explore tumor development and treatment effects in vivo, we analyze multi-omics data generated from mouse models, including xenografts and genetically induced cancers. These datasets are complex, encompassing multiple axes of variation such as treatment regimens, time points, and tumor subtypes. To disentangle these factors, we develop tailored probabilistic latent variable models (LVMs) that reveal how sources of variability interact and which molecular features are relevant to human disease.
Recent projects:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Multi-Omics combined with &lt;strong>lineage tracing&lt;/strong> technology now allow us to quantify the clonal connectivity between different cell populations and infer the temporal dynamics of cell populations. Using mechanistic modeling, we can uncover the directionality of differentiation trajectories and the dynamical properties of the clones [&lt;a href="https://www.biorxiv.org/content/10.1101/2025.09.10.674954v1.full.pdf" target="_blank" rel="noopener">pdf&lt;/a>].&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Analyzing cancerous mouse models provides valuable insights for developing &lt;strong>personalized oncology&lt;/strong> approaches. We will integrate patient data at an early stage in this process using a forward and reverse translation technique. This method ensures that the results are clinically relevant and enables us to identify patients who are eligible for a new treatment. For example, we are working on a TRR project that investigates how ubiquitination impacts DNA damage repair in AML in order to identify a new anticancer target [&lt;a href="https://ubiqancer.de/project/a13/" target="_blank" rel="noopener">project&lt;/a>].&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Interpretable Integration of Multi-Omics Data</title><link>https://mlo-lab.github.io/project/multi-omics/</link><pubDate>Tue, 10 Jun 2025 22:11:00 +0200</pubDate><guid>https://mlo-lab.github.io/project/multi-omics/</guid><description>&lt;p>Understanding the complexity of cancer requires methods that can integrate equally complex biological data. In our lab, we are committed to developing probabilistic models that bring together multiple molecular layers, including genomics, epigenomics, transcriptomics, proteomics and metabolomics, to provide a holistic view of each patient. These models uncover hidden structure by capturing both shared and modality-specific variation, allowing us to reduce noise and reveal biologically meaningful patterns. By modeling system-level responses to perturbations such as drug treatments or environmental changes, we aim to generate representations that are not only statistically robust but also interpretable, enabling new biological insights that can be directly validated and translated into clinical understanding.&lt;/p>
&lt;h3 id="muvi">MuVI&lt;/h3>
&lt;p>MuVI is a general-purpose probabilistic latent variable model for multi-omics integration that incorporates prior biological knowledge into its structure. It uses pathway annotations, gene sets, or cell-type signatures to guide the discovery of latent factors that explain variation across different data types. Even when this prior knowledge is noisy or incomplete, MuVI is able to learn biologically relevant dimensions, enabling scientists to interpret the sources of variation in the data more clearly and to relate them to known mechanisms.
&lt;img src="muvi.png" alt="MuVI">&lt;/p>
&lt;h3 id="music">MUSIC&lt;/h3>
&lt;p>MUSIC (MUltiview baySIan tensor deComposition) extends probabilistic modeling to high-dimensional array data, such as time-series or condition-specific measurements. It jointly decomposes collections of heterogeneous tensors, e.g. patient × gene × time or patient × protein × condition, into shared and modality-specific components. With structured sparsity priors and efficient variational inference, MUSIC scales to large datasets, handles missing data, and yields interpretable embeddings. We have applied it to cancer drug-response studies and single-cell leukemia data, where it revealed meaningful molecular signatures associated with disease pathways.&lt;/p>
&lt;h3 id="momo-gp">MOMO-GP&lt;/h3>
&lt;p>MOMO-GP (Multi-Omic Multi-output Gaussian Processes) addresses the challenge of learning interpretable representations from single-cell multi-omics data, which are typically high-dimensional, sparse, and nonlinear. Unlike traditional methods that trade off interpretability for modeling power, MOMO-GP combines neural networks with Gaussian Processes to achieve both. It learns separate latent embeddings for cells and features, as well as shared and modality-specific components in the multi-view setting. By modeling gene relevance explicitly, MOMO-GP connects cell clusters to marker genes, making the learned structure readily interpretable in biological terms.&lt;/p>
&lt;h3 id="joana">JOANA&lt;/h3>
&lt;p>JOANA is a probabilistic model for pathway enrichment analysis (PEA) that overcomes limitations of classical approaches like Over-Representation Analysis (ORA) and Functional Class Scoring (FCS). While methods such as GSEA work with continuous scores, they typically operate on a single omics layer and can yield overly broad sets of enriched pathways. JOANA improves on this by modeling enrichment scores across multiple omics layers using mixtures of beta distributions within a Bayesian framework. This allows it to estimate the probability of pathway enrichment both within and across modalities, yielding higher precision and more biologically relevant results.&lt;/p>
&lt;h3 id="mofaflex">MOFAFLEX&lt;/h3>
&lt;p>MOFAFLEX is our upcoming framework for flexible and interpretable multi-omics integration. Designed to generalize the principles behind models like MuVI and MUSIC, MOFAFLEX supports heterogeneous data types, modular priors, and scalable inference. Its architecture allows for tailored modeling of real-world datasets, balancing interpretability with modeling flexibility. MOFAFLEX is currently under active development and will provide a unified foundation for future applications in cancer biology and beyond.
&lt;img src="mofaflex.png" alt="MOFA-FLEX">&lt;/p></description></item></channel></rss>