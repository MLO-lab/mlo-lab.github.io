<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects | MLO Lab</title><link>https://mlo-lab.github.io/project/</link><atom:link href="https://mlo-lab.github.io/project/index.xml" rel="self" type="application/rss+xml"/><description>Projects</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2025 MLO Lab</copyright><lastBuildDate>Tue, 22 Mar 2022 16:54:16 +0100</lastBuildDate><image><url>https://mlo-lab.github.io/media/logo_huedbb8239ffd36c55e33765ff7c80fb90_78702_300x300_fit_lanczos_2.png</url><title>Projects</title><link>https://mlo-lab.github.io/project/</link></image><item><title>MuVI</title><link>https://mlo-lab.github.io/project/muvi/</link><pubDate>Tue, 22 Mar 2022 16:54:16 +0100</pubDate><guid>https://mlo-lab.github.io/project/muvi/</guid><description>&lt;p>Many real-world systems are described not only by data from a single source but via multiple data views. In genomic medicine, for instance, a patient can be described by data from different molecular layers. This raises the need for multi-view models that are able to disentangle variation within and across data views in an interpretable manner. Latent variable models with structured sparsity are a commonly used tool to address this modeling task but interpretability is cumbersome since it requires a direct inspection and interpretation of each factor via a specialized domain expert. Here, we propose MuVI, a novel approach for domain-informed multi-view latent variable models, facilitating the analysis of multi-view data in an inherently explainable manner. We demonstrate that our model (i) is able to integrate noisy domain expertise in from of feature sets, (ii) is robust to noise in the encoded domain knowledge, (iii) results in identifiable factors and (iv) is able to infer interpretable and biologically meaningful axes of variation in real-world multi-view datasets.&lt;/p>
&lt;p>Get started right away with &lt;a href="https://github.com/MLO-lab/MuVI" target="_blank" rel="noopener">MuVI&lt;/a>!&lt;/p></description></item><item><title>Computational single-cell biology</title><link>https://mlo-lab.github.io/project/single-cell/</link><pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate><guid>https://mlo-lab.github.io/project/single-cell/</guid><description>&lt;h2 id="single-cell-rna-seq">Single-cell RNA-seq&lt;/h2>
&lt;p>One research focus of MLO is on the development of application driven probabilistic machine-learning methods for analyzing high-throughput single-cell RNA-seq data.
Single-cell RNA sequencing (scRNA-seq) has become a widely used routine assay and recent scRNA-seq protocols now allow to obtain an unbiased profile of transcriptional heterogeneity at a genome-wide scale, which can be scaled to large datasets with up to millions of cells.
Analysis of such data is challenging: As the intrinsic cellular state of individual cells cannot be directly assayed, cell states need to be inferred from the transcriptional profiling data itself. To this end, single-cell profiling data pose new challenges and opportunities to derive powerful latent variable models (LVMs) that help to exploit large datasets.&lt;/p>
&lt;h3 id="visualization-of-latent-cell-states">Visualization of latent cell states&lt;/h3>
&lt;p>We have developed several tools tailored towards inferring and visualizing internal cell states. This includes inferring the internal cell-cycle state of individual cells via Gaussian Process Latent Variabe Models (GPLVM), as well as GPLVM-based identification of cell subpopulations. In addition, we have created tools based on diffusion maps that allow to recover the intrinsic order of cels, e.g. in terms of their differentiation state.&lt;/p>
&lt;h3 id="identification-of-sources-of-cell-cell-variation">Identification of sources of cell-cell variation&lt;/h3>
&lt;p>Cell-cell variability in terms of gene expression results from a variety of potential sources, including technical noise, biological variation of interest and unwanted biologicl variation (e.g. mitochonrial genes, cell cycle state, etc.). To disentangle these sources of variation, we designed slalom, an interpretable latent variable model that addresses three key tasks in computational scRNA-seq&lt;/p>
&lt;ul>
&lt;li>Disentagling biological and technical sources of variation&lt;/li>
&lt;li>Visualizing the pathways driving cell-cell variation&lt;/li>
&lt;li>Refining pathway annotations in an experiment-specific manner&lt;/li>
&lt;/ul></description></item><item><title>Multi-omics data integration</title><link>https://mlo-lab.github.io/project/mofa/</link><pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate><guid>https://mlo-lab.github.io/project/mofa/</guid><description>&lt;p>Multi‐omics studies promise the improved characterization of biological processes across molecular layers. However, methods for the integration of the resulting heterogeneous data sets are lacking.
We develop tools and algorithms for the supervised as well as unsupervised integration of such data.&lt;/p>
&lt;h2 id="unsupervised-data-integration">Unsupervised data integration&lt;/h2>
&lt;p>For example, we present Multi‐Omics Factor Analysis (MOFA), an unsupervised computational method for discovering the principal sources of variation in multi‐omics data sets. MOFA infers a set of (hidden) factors that capture biological and technical sources of variability. It disentangles axes of heterogeneity that are shared across multiple modalities and those specific to individual data modalities. The learnt factors enable a variety of downstream analyses, including identification of sample subgroups, data imputation and the detection of outlier samples.
We applied MOFA to a cohort of 200 patient samples of chronic lymphocytic leukaemia, profiled for somatic mutations, RNA expression, DNA methylation and ex vivo drug responses. MOFA identified major dimensions of disease heterogeneity, including immunoglobulin heavy‐chain variable region status, trisomy of chromosome 12 and previously underappreciated drivers, such as response to oxidative stress.
In close collaboration with the Oellerich group in Frankfurt, we use MOFA to elucidate the proteogenomic landscape in a range of cancers.
In addition, we use MOFA to analyse single‐cell multi‐omics data, for example identifying coordinated transcriptional and epigenetic changes along cell differentiation and analysing the epigenetic landscape during mammalian germ layer specification.&lt;/p>
&lt;h2 id="supervised-analysis-of-multi-omics-data">Supervised analysis of multi-omics data&lt;/h2>
&lt;p>In addition to these unsupevised approaches, we also develop tools for integrative gene-set enrichment analyses in supervised multi-omics settings. In particular, our algorithm MONA and its accompanying webservice RAMONA use a Bayesian approach with a computationally efficient method to approximate the marginal posteriors of ontology terms, given lists of genes responding to experimental conditions. MONA is designed to easily handle any combination of molecular levels in a modular fashion.&lt;/p></description></item><item><title>Probabilistic latent variable models</title><link>https://mlo-lab.github.io/project/lvmodels/</link><pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate><guid>https://mlo-lab.github.io/project/lvmodels/</guid><description>&lt;p>Latent variable models (LVMs) are a statistical tool to infer an unobserved, hidden state of a complex (e.g. biological) system based on observable data that is often high-dimensional. To this end, a high-dimensional dataset of correlated observations is reduced into a low-dimensional dataset of uncorrelated and interpretable latent variables. Probabilistic approaches allow for a principled way to disentangle distinct sources of variation and explicitly model dependencies between features as well as samples.&lt;/p>
&lt;h2 id="accounting-for-dependencies-between-genes-in-lvms">Accounting for dependencies between genes in LVMs&lt;/h2>
&lt;ul>
&lt;li>Standard latent variable models only model dependencies between samples&lt;/li>
&lt;li>Can we make dependencies between features (genes) explicit?&lt;/li>
&lt;li>Use framework of Gaussian Process Latent Variable Models (GP-LVM)&lt;/li>
&lt;li>Probabilistic kernel PCA via GP regression with unobserved input&lt;/li>
&lt;li>Introduce kernel to model covariance between genes&lt;/li>
&lt;li>Learn latent variables for genes and samples and connect via Kronecker Product&lt;/li>
&lt;li>Apply to matrix completion tasks&lt;/li>
&lt;/ul>
&lt;p>Reference: Yang &amp;amp; Buettner, UAI 2021 (in revision)&lt;/p>
&lt;h2 id="hierarchical-autoencoders-for-domain-generalisation">Hierarchical autoencoders for Domain Generalisation&lt;/h2>
&lt;ul>
&lt;li>Learn VAE to disentangle domain-specific information form class-specific information and residual variance&lt;/li>
&lt;li>Place Dirichlet prior on domain representation&lt;/li>
&lt;li>Learn “topics” that describe domain structure in unsupervised manner&lt;/li>
&lt;li>Interpretable model for unsupervised domain generalisation&lt;/li>
&lt;/ul>
&lt;p>Reference: Sun &amp;amp; Buettner, ICLR Workshop on robustML, 2021&lt;/p></description></item><item><title>Uncertainty-aware deep learning in the real world</title><link>https://mlo-lab.github.io/project/calibration/</link><pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate><guid>https://mlo-lab.github.io/project/calibration/</guid><description>&lt;p>Due to their high predictive power, deep neural networks are increasingly being used as part of decision
making systems in real world applications. However, such systems require not only high accuracy, but also reliable and calibrated uncertainty estimates. Especially in safety critical applications in medicine where average case performance is insufficient, practitioners need to have access to reliable predictive uncertainty during the entire lifecycle of the model. This means confidence scores (or
predictive uncertainty) should be meaningful not only for in-domain predictions, but also under gradual
domain drift where the distribution of the input samples gradually changes from in-domain to truly out-ofdistribution (OOD). In healthcare, common examples of such domain shift scenarios are a patient demographic that changes over time or new hospitals in which a model is to be deployed.&lt;/p>
&lt;h2 id="towards-trustworthy-predictions-from-deep-neural-networks-with-fast-adversarial-calibration">Towards Trustworthy Predictions from Deep Neural Networks with Fast Adversarial Calibration&lt;/h2>
&lt;p>Here, we propose an efficient yet general modelling approach for obtaining wellcalibrated, trustworthy probabilities for samples obtained after a domain shift. We introduce a new training strategy combining an entropy-encouraging loss term with an adversarial calibration loss term and demonstrate that this results in well-calibrated and technically trustworthy predictions for a wide range of domain drifts. We comprehensively evaluate previously proposed approaches on different data modalities, a large range of data sets including sequence data, network architectures and perturbation strategies. We observe
that our modelling approach substantially outperforms existing state-of-the-art approaches, yielding well-calibrated predictions under domain drift.&lt;/p>
&lt;p>&lt;em>Reference: Tomani &amp;amp; Buettner, AAAI 2021&lt;/em>&lt;/p>
&lt;h2 id="post-hoc-uncertainty-calibration-for-domain-drift-scenarios">Post-hoc Uncertainty Calibration for Domain Drift Scenarios&lt;/h2>
&lt;p>We address the problem of uncertainty calibration. While standard deep neural networks typically yield uncalibrated predictions, calibrated confidence scores that are representative of the true likelihood of a prediction can be achieved using post-hoc calibration methods. However, to date the focus of these approaches has been on in-domain calibration. Our contribution is two-fold.
First, we show that existing post-hoc calibration methods yield highly over-confident predictions under domain shift. Second, we introduce a simple strategy where perturbations are applied to samples in the validation set before performing the post-hoc calibration step. In extensive experiments, we demonstrate that this perturbation step results in substantially better calibration under domain shift on a wide range of architectures and modelling tasks.&lt;/p>
&lt;p>&lt;em>Reference: Tomani, Gruber, Erdem, Cremers &amp;amp; Buettner, CVPR 2021 (oral presentation)&lt;/em>&lt;/p>
&lt;h2 id="parameterized-temperature-scaling-for-boosting-the-expressive-power-in-post-hoc-uncertainty-calibration">Parameterized Temperature Scaling for Boosting the Expressive Power in Post-Hoc Uncertainty Calibration&lt;/h2>
&lt;p>We address the problem of uncertainty calibration and introduce a novel calibration
method, Parametrized Temperature Scaling (PTS). Standard deep neural networks typically yield uncalibrated predictions, which can be transformed into calibrated confidence
scores using post-hoc calibration methods. In this contribution, we demonstrate that the
performance of accuracy-preserving state-ofthe-art post-hoc calibrators is limited by their
intrinsic expressive power. We generalize temperature scaling by computing predictionspecific temperatures, parameterized by a neural network. We show with extensive experiments that our novel accuracy-preserving approach consistently outperforms existing algorithms across a large number of model
architectures, datasets and metrics.&lt;/p>
&lt;p>&lt;em>Reference: Tomani, Cremers &amp;amp; Buettner, arxiv 2021 (in submission)&lt;/em>&lt;/p></description></item></channel></rss>