<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.1.0 for Hugo"><meta name=author content="Florian Buettner"><meta name=description content="Machine Learning in Oncology"><link rel=alternate hreflang=en-us href=https://mlo-lab.github.io/post/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#1565c0"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload="this.media='all'"><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload="this.media='all'"><link rel=stylesheet href=/css/wowchemy.ecfcc756a0a1184b7d80a75bdb576bd6.css><link rel=alternate href=/post/index.xml type=application/rss+xml title="MLO Lab"><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/media/icon_hu8d9314a239469466677e43b6690121ff_611496_32x32_fill_lanczos_center_2.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu8d9314a239469466677e43b6690121ff_611496_180x180_fill_lanczos_center_2.png><link rel=canonical href=https://mlo-lab.github.io/post/><meta property="twitter:card" content="summary"><meta property="og:site_name" content="MLO Lab"><meta property="og:url" content="https://mlo-lab.github.io/post/"><meta property="og:title" content="Posts | MLO Lab"><meta property="og:description" content="Machine Learning in Oncology"><meta property="og:image" content="https://mlo-lab.github.io/media/logo_huedbb8239ffd36c55e33765ff7c80fb90_78702_300x300_fit_lanczos_2.png"><meta property="twitter:image" content="https://mlo-lab.github.io/media/logo_huedbb8239ffd36c55e33765ff7c80fb90_78702_300x300_fit_lanczos_2.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2025-12-04T13:58:55+01:00"><title>Posts | MLO Lab</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=6370009740e1eb2ee0b7974f10ecc91f><script src=/js/wowchemy-init.min.226a9011996d125bf3fe4a5f22353a49.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/><img src=/media/logo_huedbb8239ffd36c55e33765ff7c80fb90_78702_0x70_resize_lanczos_2.png alt="MLO Lab"></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/><img src=/media/logo_huedbb8239ffd36c55e33765ff7c80fb90_78702_0x70_resize_lanczos_2.png alt="MLO Lab"></a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>About</span></a></li><li class=nav-item><a class=nav-link href=/#news><span>News</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#people><span>Team</span></a></li><li class=nav-item><a class=nav-link href=/#teaching><span>Teaching</span></a></li><li class=nav-item><a class=nav-link href=/#jobs><span>Jobs</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><div class="universal-wrapper pt-3"><h1>Posts</h1></div><div class=universal-wrapper><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/buettner-posterior-inverse-problems/>Application-driven validation of posteriors in inverse problems, published in Medical Image Analysis.</a></div><a href=/post/buettner-posterior-inverse-problems/ class=summary-link><div class=article-style>We present the first systematic framework for application-driven validation of posterior-based methods in inverse problems. Adapting concepts from object detection enables mode-centric validation with interpretable, application-focused metrics, demonstrated on multiple medical imaging use cases.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/author/florian-buettner/>Florian Buettner</a></span></div><span class=article-date>Apr 1, 2025</span>
<span class=middot-divider></span><span class=article-reading-time>1 min read</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href="https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841524X00092/1-s2.0-S1361841525000222/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEKf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCI8bdlBYJ6YkK%2Bgc2Fa80XR4IpaM%2B08vUt1HyCuFAS5wIgBlh4gMocmCDrknoNdSXLP%2FCsiqzoJrdNayXt0hdDQ1IqsgUIbxAFGgwwNTkwMDM1NDY4NjUiDM8rfWnwns8n6gKd%2BCqPBdvuuZFazWD96HjAmCeeC1ku7riD0wG63udDsHb4QFunCsnjaM%2BVnF2Rer26%2BiPRnxGlOmUyV4qlC39CK1Sz4XAWLvT9PQMKqLbfG%2B7IeX7ytoqqnBxqoqrKU%2FZZwtNZSSON1xTFjYDqLfzsHSvh0wkjFgT%2BQYoE0U38Sybx3uelsDf1YBsLFscg2yb1aXA59KZnj4560AIvWvDdTGkOY4Co6aA34X3DimNge9g%2Fyj9eWcVcv4S87ctxvYbhi4GEgvwq3oYPpZQ5JBw7wxxX%2FulDCm5%2BreH7KnUO1indBHbxd%2BP%2Bb1GAGb8%2FWki%2FUu%2FsotndGxK%2FytEkn%2FkSk7TdN6yom95NzV5sqiTDDxhFNNN5IWZPNsO4WvU9gFETYH8cvLHxgYvElu4YZva%2BAErxYtek1Q9lyEafw9xHuX7qayLbmotpyCOF2AN7aT4fDNYn7KTx7fQacHj8rDY3wW0kdKHLY0iVKPIJiFLEmKA7IUBdLLQ2urvPdu30Svx0L7gkRDdYG917VlcAadP2UCVH2owMlv3ffMF9%2FT9G22l6aNMctkUF6Nst%2BCxnjxkPcCygZRWLjxd5vkupOcpYpC8nOnDpym07%2BsFSByll0rKK1l%2F%2F%2Fv2IZulbGg4n6vw96DPq8H%2B448dNWTUjt55NJ5VPeG99tzyrO6wchG5p%2B0us4ZWiwEtvgo3%2FXtmH3PaF6WkC0ePULxH08eJWLqI2gIl15Jh93AO20NmnDBrid4Y9cpj9xSOCXvlKyHk4glCxz8d9OZ6z%2BLUgCOGFLRB8L234X2lss4G%2B6r8eMQpM4LGaQYNxI6W14nQxmrSWACgifYoJq28ZNAf02EZMVHmKd8XF6KO8cLrK8RWnnlqLIL6IxjgwrPGWyQY6sQEAqjBg0tlIyAel%2BIyVPit7R0uT5S1n8ih7tk0p9Ksjbyq5GeurE0ZpqOBVTlTvm%2BIJBWYlY%2FrtGgraU4eNLbcpfe%2F8paGZVQmTQOqX9fIMYiCjyLemS1xyR6G5MDzZ0e2eykH9ed%2B7uJVuNZqzGUMR0UDfdSStkQeKJU2j%2FA%2BP8zE2prIDmveyQ0INciYn4godG9j%2F4A9p7JPeBwMWQ3SRwU6uZ2EvNcdVL1MGf7dx4FY%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251125T142106Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYWXNX3Q3X%2F20251125%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=39577e8a7bccdba7634daf38e4ec66d02e9524705a87d8380de7299035e5e021&hash=032ad91c4f56da9967263e1757ba07884841eaa4f48692064fb736e102bf494f&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1361841525000222&tid=spdf-8ed06d5c-5150-4aa9-a314-5202ceeb29bc&sid=9cf63b075956f34c942a7d144b1d765e2d78gxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=1e03590254560703535759&rr=9a41ca618890c7dc&cc=de" target=_blank rel=noopener>PDF</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/buettner-lvlm-aided-visiual-alignment/>Our paper on bidirectional human-AI visual alignment is out at the ICLR 2025 Workshop!</a></div><a href=/post/buettner-lvlm-aided-visiual-alignment/ class=summary-link><div class=article-style>We introduce LVLM-Aided Visual Alignment (LVLM-VA), which aligns small vision models with human domain knowledge using large vision-language models. A bidirectional interface translates model behavior into natural language and expert instructions into image-level critiques, improving performance while reducing fine-grained feedback needs.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/author/florian-buettner/>Florian Buettner</a></span></div><span class=article-date>Mar 6, 2025</span>
<span class=middot-divider></span><span class=article-reading-time>1 min read</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/pdf?id=SM16xgEjos" target=_blank rel=noopener>PDF</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/serra-predictive-uncertainty-catastrophic-forgetting/>Forget forgetting — our TMLR paper shows how uncertainty helps models keep their memory straight!</a></div><a href=/post/serra-predictive-uncertainty-catastrophic-forgetting/ class=summary-link><div class=article-style>We analyze how predictive uncertainty can guide memory management to mitigate catastrophic forgetting and introduce a generalized-variance–based uncertainty measure. Uncertainty-aware sampling improves retention across tasks. Published in the Journal of Transactions on Machine Learning Research.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/author/giuseppe-serra/>Giuseppe Serra</a></span></div><span class=article-date>Mar 4, 2025</span>
<span class=middot-divider></span><span class=article-reading-time>1 min read</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/pdf?id=dczXe0S1oL" target=_blank rel=noopener>PDF</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/buettner-iupm-intervention/>New at AISTATS: IUPM — a label-free method for reliable model monitoring under drift.</a></div><a href=/post/buettner-iupm-intervention/ class=summary-link><div class=article-style>We propose IUPM, a label-free method for tracking performance under gradual distribution shifts using optimal transport. IUPM quantifies uncertainty in its estimates and guides targeted labeling to restore reliability, outperforming existing baselines across scenarios.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/author/florian-buettner/>Florian Buettner</a></span></div><span class=article-date>Jan 22, 2025</span>
<span class=middot-divider></span><span class=article-reading-time>1 min read</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://raw.githubusercontent.com/mlresearch/v258/main/assets/koebler25a/koebler25a.pdf target=_blank rel=noopener>PDF</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/serra-continous-learning-memory-managment/>Our ICLR paper proves that not everything needs to be forgotten — tackling catastrophic forgetting head-on!</a></div><a href=/post/serra-continous-learning-memory-managment/ class=summary-link><div class=article-style>We propose an uncertainty-aware memory-based approach for online Federated Continual Learning. Using a Bregman Information estimator to guide selective replay, the method reduces catastrophic forgetting across modalities while preserving privacy and communication efficiency.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/author/giuseppe-serra/>Giuseppe Serra</a></span></div><span class=article-date>Jan 22, 2025</span>
<span class=middot-divider></span><span class=article-reading-time>1 min read</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/pdf?id=f65RuQgVlp" target=_blank rel=noopener>PDF</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/kuhn-unsupervised-shortcut-transformers/>Unsupervised and efficient — our latest work exposes and mitigates shortcut learning!</a></div><a href=/post/kuhn-unsupervised-shortcut-transformers/ class=summary-link><div class=article-style>We introduce an unsupervised framework to detect and mitigate shortcut learning in transformers. The method improves both worst-group and average accuracy while reducing annotation effort, offering interpretable insights for experts and running efficiently on consumer hardware.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/author/lukas-kuhn/>Lukas Kuhn</a></span></div><span class=article-date>Jan 1, 2025</span>
<span class=middot-divider></span><span class=article-reading-time>1 min read</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/pdf/2501.00942 target=_blank rel=noopener>PDF</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/buettner-metabolic-changes-graph-embeddings/>Our latest work on deep learning for metabolomics just appeared in Scientific Reports!</a></div><a href=/post/buettner-metabolic-changes-graph-embeddings/ class=summary-link><div class=article-style>We introduce GEMNA, a deep learning framework for mass spectrometry–based metabolomics that uses graph and edge embeddings with anomaly detection. GEMNA outperforms traditional tools in untargeted studies, producing clearer clusters and improved biological insights.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/author/florian-buettner/>Florian Buettner</a></span></div><span class=article-date>Nov 28, 2024</span>
<span class=middot-divider></span><span class=article-reading-time>1 min read</span></div></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/gruber-diagnostic_image_generators/>Rounding out our research hat trick with new insights into interpretable image synthesis!</a></div><a href=/post/gruber-diagnostic_image_generators/ class=summary-link><div class=article-style>Our latest work presents a new approach to disentangle image generation performance by decomposing cosine similarity into cluster-level contributions using central kernel alignment. This allows us to quantify how different pixel regions contribute to overall image quality, enabling more fine-grained evaluation and improved explainability of generative models across real-world use cases.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/author/sebastian-gruber/>Sebastian Gruber</a></span></div><span class=article-date>Sep 2, 2024</span>
<span class=middot-divider></span><span class=article-reading-time>1 min read</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/pdf/2409.01314 target=_blank rel=noopener>PDF</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/buettner-feature-shift-performance/>Our framework for explanatory model monitoring was featured at KDD</a></div><a href=/post/buettner-feature-shift-performance/ class=summary-link><div class=article-style>We introduce Explanatory Performance Estimation (XPE), a method that explains model behavior under feature shifts by linking performance changes to interpretable input characteristics using Optimal Transport and Shapley Values. This enables explanatory model monitoring across image, audio, and tabular data.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/author/florian-buettner/>Florian Buettner</a></span></div><span class=article-date>Aug 24, 2024</span>
<span class=middot-divider></span><span class=article-reading-time>1 min read</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/pdf/2408.13648 target=_blank rel=noopener>PDF</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/buettner-expert-eyes-algning-industrial-ai/>Our latest paper at HCI explores how human gaze can make AI more interpretable and reliable!</a></div><a href=/post/buettner-expert-eyes-algning-industrial-ai/ class=summary-link><div class=article-style>We show how integrating human gaze information aligns human and machine attention, improving model robustness and explainability. Demonstrated on real-world visual quality inspection, the approach highlights the value of explicit human knowledge in training trustworthy AI.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=/author/florian-buettner/>Florian Buettner</a></span></div><span class=article-date>Jul 29, 2024</span>
<span class=middot-divider></span><span class=article-reading-time>1 min read</span></div></div></div><div class=ml-3></div></div><nav><ul class="pagination justify-content-center"><li class=page-item><a class=page-link href=/post/>&#171;</a></li><li class=page-item><a class=page-link href=/post/page/3/>&#187;</a></li></ul></nav></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by><a href=/terms/>Impressum</a></p><p class=powered-by>© 2026 MLO Lab &#183;
Powered by the
<a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Academic theme</a> for
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a>.
<span class=float-right aria-hidden=true><a href=# id=back_to_top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i>Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i>Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script><script src=/en/js/wowchemy.min.b61a8f62b6e5c0cd322c8158c5b5dfb6.js></script><script async defer src=https://buttons.github.io/buttons.js></script></body></html>