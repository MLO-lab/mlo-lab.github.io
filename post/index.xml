<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts | MLO Lab</title><link>https://mlo-lab.github.io/post/</link><atom:link href="https://mlo-lab.github.io/post/index.xml" rel="self" type="application/rss+xml"/><description>Posts</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2025 MLO Lab</copyright><lastBuildDate>Tue, 25 Jul 2023 22:16:23 +0200</lastBuildDate><image><url>https://mlo-lab.github.io/media/logo_huedbb8239ffd36c55e33765ff7c80fb90_78702_300x300_fit_lanczos_2.png</url><title>Posts</title><link>https://mlo-lab.github.io/post/</link></image><item><title>Paper accepted at ICML CompBio 2023!</title><link>https://mlo-lab.github.io/post/qoku-cellij-icml-23/</link><pubDate>Tue, 25 Jul 2023 22:16:23 +0200</pubDate><guid>https://mlo-lab.github.io/post/qoku-cellij-icml-23/</guid><description>&lt;p>&lt;strong>Paper accepted! Our latest work on developing a versatile framework for rapid prototyping and training of a wide range of factor analysis models for multi-omics data got accepted at this year&amp;rsquo;s ICML workshop on computational biology!&lt;/strong>&lt;/p></description></item><item><title>ERC Consolidator Grant for Florian!</title><link>https://mlo-lab.github.io/post/buettner-erc-grant-23/</link><pubDate>Sun, 22 Jan 2023 16:16:26 +0200</pubDate><guid>https://mlo-lab.github.io/post/buettner-erc-grant-23/</guid><description>&lt;p>&lt;strong>With 2 million Euros in funding from the European Research Council, we will be developing AI models to support doctors in the diagnosis and treatment of cancer. &lt;a href="https://www.dkfz.de/de/presse/pressemitteilungen/2023/dkfz-pm-23-07-ERC-Consolidator-Grant-fuer-DKTK-Forscher-Florian-Buettner.php" target="_blank" rel="noopener">Read more&lt;/a>!&lt;/strong>&lt;/p></description></item><item><title>Paper accepted at AISTATS 2023!</title><link>https://mlo-lab.github.io/post/gruber-uncertainty-aistats-23/</link><pubDate>Fri, 20 Jan 2023 16:16:03 +0200</pubDate><guid>https://mlo-lab.github.io/post/gruber-uncertainty-aistats-23/</guid><description>&lt;p>&lt;strong>Paper accepted! Our latest work on a general bias-variance decomposition for proper scores got accepted at this year&amp;rsquo;s AISTATS conference!&lt;/strong>&lt;/p></description></item><item><title>Paper accepted at AISTATS 2023!</title><link>https://mlo-lab.github.io/post/qoku-encoding-aistats-23/</link><pubDate>Fri, 20 Jan 2023 16:15:47 +0200</pubDate><guid>https://mlo-lab.github.io/post/qoku-encoding-aistats-23/</guid><description>&lt;p>&lt;strong>Paper accepted! Our latest work on multi-view latent variable models with structured sparsity got accepted at this year&amp;rsquo;s AISTATS conference!&lt;/strong>&lt;/p></description></item><item><title>Paper accepted at AAAI 2023!</title><link>https://mlo-lab.github.io/post/hekler-test-aaai-23/</link><pubDate>Sat, 14 Jan 2023 16:15:05 +0200</pubDate><guid>https://mlo-lab.github.io/post/hekler-test-aaai-23/</guid><description>&lt;p>&lt;strong>Paper accepted! Our latest work on quantifying uncertainty under real-world conditions got accepted at this year&amp;rsquo;s AAAI conference on artificial intelligence!&lt;/strong>&lt;/p></description></item><item><title>Paper accepted at ECCV 2022!</title><link>https://mlo-lab.github.io/post/tomani-eccv-22/</link><pubDate>Fri, 08 Jul 2022 17:13:49 +0200</pubDate><guid>https://mlo-lab.github.io/post/tomani-eccv-22/</guid><description>&lt;p>&lt;strong>Paper accepted! Our latest work on boosting the expressive power in post-hoc uncertainty calibration got accepted at this year&amp;rsquo;s ECCV!&lt;/strong>&lt;/p></description></item><item><title>Paper accepted at Cancer Cell 2022!</title><link>https://mlo-lab.github.io/post/wolf-aml-cancercell-22/</link><pubDate>Fri, 08 Jul 2022 16:33:37 +0200</pubDate><guid>https://mlo-lab.github.io/post/wolf-aml-cancercell-22/</guid><description>&lt;p>&lt;strong>Paper accepted! Our latest work on characterizing proteogenomic subtypes of AML got accepted at this year&amp;rsquo;s Cancer Cell!&lt;/strong>&lt;/p></description></item><item><title>Paper accepted at KDD 2021!</title><link>https://mlo-lab.github.io/post/spexlvm-kdd/</link><pubDate>Tue, 13 Jul 2021 16:30:04 +0200</pubDate><guid>https://mlo-lab.github.io/post/spexlvm-kdd/</guid><description>&lt;p>Latent variable models are powerful statistical tools that can uncover relevant variation between patients or cells, by inferring unobserved hidden states from observable high-dimensional data. A major shortcoming of current methods, however, is their inability to learn sparse and interpretable hidden states. Additionally, in settings where partial knowledge on the latent structure of the data is readily available, a statistically sound integration of prior information into current methods is challenging. To address these issues, we propose spex-LVM, a factorial latent variable model with &lt;strong>s&lt;/strong>parse &lt;strong>p&lt;/strong>riors to encourage the inference of &lt;strong>ex&lt;/strong>plainable factors driven by domain-relevant information. spex-LVM utilizes existing knowledge of curated biomedical pathways to automatically assign annotated attributes to latent factors, yielding interpretable results tailored to the corresponding domain of interest. Evaluations on simulated and real single-cell RNA-seq datasets demonstrate that our model robustly identifies relevant structure in an inherently explainable manner, distinguishes technical noise from sources of biomedical variation, and provides data-driven adaptations of existing pathway annotations.&lt;/p></description></item><item><title>Paper accepted at UAI!</title><link>https://mlo-lab.github.io/post/paper-uai-yang/</link><pubDate>Thu, 20 May 2021 16:59:59 +0200</pubDate><guid>https://mlo-lab.github.io/post/paper-uai-yang/</guid><description>&lt;p>&lt;strong>Paper accepted! Our latest work on multi-output Gaussian Process Latent Variable models got accepted at this year&amp;rsquo;s UAI!&lt;/strong>&lt;/p></description></item><item><title>Workshop on XAI and Trustworthiness in Healthcare at KDD 2021!</title><link>https://mlo-lab.github.io/post/workshop/</link><pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate><guid>https://mlo-lab.github.io/post/workshop/</guid><description>&lt;p>&lt;strong>We organize a workshop at this year&amp;rsquo;s KDD&lt;/strong>&lt;/p>
&lt;p>Check out the workshop website &lt;a href="https://dshealthkdd.github.io/dshealth-2021/" target="_blank">here&lt;/a>.
Paper submission deadline is 10th May 2021.&lt;/p>
&lt;h1 id="overview">Overview&lt;/h1>
&lt;p>Healthcare is, traditionally, a knowledge-driven enterprise with an enormous amount of data - both structured and unstructured. These data can impact positively on the development of data-driven health care including precision medicine and precision public health. In recent years, large scale medical/clinical datasets, such as “omics” data and radiology reports are increasingly available. We have also witnessed an increasing number of successful AI/ML applications using such datasets to address problems such as drug repurposing and preliminary screening of radiology reports. To facilitate the adoption of such AI/ML in practice, we have simultaneously witnessed an increasing adoption/innovation of using explainability methods to analyze/present AI for Health. In this deep learning era, What is the current status of AI/ML applications in healthcare? What are the standard methods of explaining such AI models for healthcare? What are the roles of causality in AI/ML practices? What are the state-of-the-art developments in causal AI in health and health care domains? What are the limitations and how are the different facets of trust and explanations (see figure 1 below) being addressed in practice? Can knowledge-backed AI lead to more robust and interpretable models? How do data scientists and physicians apply this knowledge in collaboration and via human-centered AI approaches to further the field and improve healthcare? How are regulatory requirements for transparency and trustworthiness of models and data privacy being defined and how can they be fulfilled? After witnessing so many great achievements from deep learning lately, we propose to invite world-leading experts from both data science and healthcare to discuss and debate the path forward for practical applications of AI/ML in healthcare, including demos, early work, and critiques on the current state and the path forward for explainability and trustworthiness in AI. More specifically, we plan to attract high-quality original research from emerging areas with significant implications in healthcare and invite open discussions on controversial yet crucial topics regarding healthcare transformation&lt;/p>
&lt;h1 id="key-dates">Key dates&lt;/h1>
&lt;ul>
&lt;li>Paper Submission opens: Apr 15, 2021&lt;/li>
&lt;li>Paper Submission deadline: May 10, 2021&lt;/li>
&lt;li>Acceptance Notice: Jun 10, 2021&lt;/li>
&lt;li>Workshop Date: Aug 14, 2021&lt;/li>
&lt;/ul>
&lt;p>All deadlines correspond to 11:59 PM Hawaii Standard Time ( HST).&lt;/p></description></item></channel></rss>