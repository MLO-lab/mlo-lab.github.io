<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Giuseppe Serra | MLO Lab</title><link>https://mlo-lab.github.io/author/giuseppe-serra/</link><atom:link href="https://mlo-lab.github.io/author/giuseppe-serra/index.xml" rel="self" type="application/rss+xml"/><description>Giuseppe Serra</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© 2025 MLO Lab</copyright><lastBuildDate>Tue, 10 Jun 2025 22:46:01 +0200</lastBuildDate><image><url>https://mlo-lab.github.io/author/giuseppe-serra/avatar_hu834932a73477ae48f98151ce930926cd_460094_270x270_fill_q75_lanczos_center.jpg</url><title>Giuseppe Serra</title><link>https://mlo-lab.github.io/author/giuseppe-serra/</link></image><item><title>Trustworthy Machine Learning in Biomedical Research</title><link>https://mlo-lab.github.io/project_new/trustworthy-ml/</link><pubDate>Tue, 10 Jun 2025 22:46:01 +0200</pubDate><guid>https://mlo-lab.github.io/project_new/trustworthy-ml/</guid><description>&lt;p>As machine learning becomes increasingly central to biomedical discovery and clinical decision-making, ensuring the reliability, fairness, and interpretability of these models is critical. In our lab, we are committed to developing and applying machine learning methods that are not only accurate but also &lt;strong>trustworthy&lt;/strong>, meaning they are robust to noise, generalizable across datasets, transparent in their decision-making, and aligned with ethical and clinical standards.&lt;/p>
&lt;p>Our work spans multiple aspects of trustworthy ML, including uncertainty quantification, model calibration, interpretability, fairness in predictive models, and robustness to distributional shifts. These components are especially important in healthcare, where decisions influenced by models can have direct consequences for patients.&lt;/p>
&lt;p>In the context of multi-omics data, single-cell analysis, and quantitative imaging, we embed trustworthiness principles throughout the model development pipeline, from data preprocessing and integration to prediction and interpretation. This ensures that our computational outputs can be confidently used to guide biological insight and translational applications.&lt;/p>
&lt;h3 id="ongoing-projects">Ongoing Projects&lt;/h3>
&lt;p>&lt;em>To be completed: This section will describe specific methods, tools, or case studies currently under development in the lab that focus on trustworthy machine learning.&lt;/em>&lt;/p></description></item><item><title>Federated Continual Learning Goes Online: Leveraging Uncertainty for Modality-Agnostic Class-Incremental Learning</title><link>https://mlo-lab.github.io/publication/serra-2024-federated/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://mlo-lab.github.io/publication/serra-2024-federated/</guid><description/></item><item><title>How to Leverage Predictive Uncertainty Estimates for Reducing Catastrophic Forgetting in Online Continual Learning</title><link>https://mlo-lab.github.io/publication/serra-2024-leverage/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://mlo-lab.github.io/publication/serra-2024-leverage/</guid><description/></item></channel></rss>