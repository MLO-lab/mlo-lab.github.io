<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>domain expertise | MLO Lab</title><link>https://mlo-lab.github.io/tag/domain-expertise/</link><atom:link href="https://mlo-lab.github.io/tag/domain-expertise/index.xml" rel="self" type="application/rss+xml"/><description>domain expertise</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2025 MLO Lab</copyright><lastBuildDate>Tue, 10 Jun 2025 22:11:00 +0200</lastBuildDate><image><url>https://mlo-lab.github.io/media/logo_huedbb8239ffd36c55e33765ff7c80fb90_78702_300x300_fit_lanczos_2.png</url><title>domain expertise</title><link>https://mlo-lab.github.io/tag/domain-expertise/</link></image><item><title>Interpretable Integration of Multi-Omics Data</title><link>https://mlo-lab.github.io/project_new/multi-omics/</link><pubDate>Tue, 10 Jun 2025 22:11:00 +0200</pubDate><guid>https://mlo-lab.github.io/project_new/multi-omics/</guid><description>&lt;p>Understanding the complexity of cancer requires making sense of equally complex biological data. In our lab, we develop probabilistic models for the integration of multi-omics datasets, where each patient is described by diverse molecular layers such as genomics, epigenomics, transcriptomics, proteomics, and metabolomics. These models uncover hidden structure in the data by capturing both shared and modality-specific sources of variation. This allows us to reduce noise, infer biologically meaningful patterns, and model system-level responses to perturbations such as drug treatments or environmental changes. Our goal is to produce representations that are not only statistically robust, but also interpretable, resulting in novel biological insights can be directly extracted and validated.&lt;/p>
&lt;h3 id="muvi">MuVI&lt;/h3>
&lt;p>MuVI is a general-purpose probabilistic latent variable model for multi-omics integration that incorporates prior biological knowledge into its structure. It uses pathway annotations, gene sets, or cell-type signatures to guide the discovery of latent factors that explain variation across different data types. Even when this prior knowledge is noisy or incomplete, MuVI is able to learn biologically relevant dimensions, enabling scientists to interpret the sources of variation in the data more clearly and to relate them to known mechanisms.
&lt;img src="muvi.png" alt="MuVI">&lt;/p>
&lt;h3 id="music">MUSIC&lt;/h3>
&lt;p>MUSIC (MUltiview baySIan tensor deComposition) extends probabilistic modeling to high-dimensional array data, such as time-series or condition-specific measurements. It jointly decomposes collections of heterogeneous tensors, e.g. patient × gene × time or patient × protein × condition, into shared and modality-specific components. With structured sparsity priors and efficient variational inference, MUSIC scales to large datasets, handles missing data, and yields interpretable embeddings. We have applied it to cancer drug-response studies and single-cell leukemia data, where it revealed meaningful molecular signatures associated with disease pathways.&lt;/p>
&lt;h3 id="momo-gp">MOMO-GP&lt;/h3>
&lt;p>MOMO-GP (Multi-Omic Multi-output Gaussian Processes) addresses the challenge of learning interpretable representations from single-cell multi-omics data, which are typically high-dimensional, sparse, and nonlinear. Unlike traditional methods that trade off interpretability for modeling power, MOMO-GP combines neural networks with Gaussian Processes to achieve both. It learns separate latent embeddings for cells and features, as well as shared and modality-specific components in the multi-view setting. By modeling gene relevance explicitly, MOMO-GP connects cell clusters to marker genes, making the learned structure readily interpretable in biological terms.&lt;/p>
&lt;h3 id="joana">JOANA&lt;/h3>
&lt;p>JOANA is a probabilistic model for pathway enrichment analysis (PEA) that overcomes limitations of classical approaches like Over-Representation Analysis (ORA) and Functional Class Scoring (FCS). While methods such as GSEA work with continuous scores, they typically operate on a single omics layer and can yield overly broad sets of enriched pathways. JOANA improves on this by modeling enrichment scores across multiple omics layers using mixtures of beta distributions within a Bayesian framework. This allows it to estimate the probability of pathway enrichment both within and across modalities, yielding higher precision and more biologically relevant results.&lt;/p>
&lt;h3 id="mofaflex">MOFAFLEX&lt;/h3>
&lt;p>MOFAFLEX is our upcoming framework for flexible and interpretable multi-omics integration. Designed to generalize the principles behind models like MuVI and MUSIC, MOFAFLEX supports heterogeneous data types, modular priors, and scalable inference. Its architecture allows for tailored modeling of real-world datasets, balancing interpretability with modeling flexibility. MOFAFLEX is currently under active development and will provide a unified foundation for future applications in cancer biology and beyond.&lt;/p></description></item><item><title>MuVI</title><link>https://mlo-lab.github.io/project/muvi/</link><pubDate>Tue, 22 Mar 2022 16:54:16 +0100</pubDate><guid>https://mlo-lab.github.io/project/muvi/</guid><description>&lt;p>Many real-world systems are described not only by data from a single source but via multiple data views. In genomic medicine, for instance, a patient can be described by data from different molecular layers. This raises the need for multi-view models that are able to disentangle variation within and across data views in an interpretable manner. Latent variable models with structured sparsity are a commonly used tool to address this modeling task but interpretability is cumbersome since it requires a direct inspection and interpretation of each factor via a specialized domain expert. Here, we propose MuVI, a novel approach for domain-informed multi-view latent variable models, facilitating the analysis of multi-view data in an inherently explainable manner. We demonstrate that our model (i) is able to integrate noisy domain expertise in from of feature sets, (ii) is robust to noise in the encoded domain knowledge, (iii) results in identifiable factors and (iv) is able to infer interpretable and biologically meaningful axes of variation in real-world multi-view datasets.&lt;/p>
&lt;p>Get started right away with &lt;a href="https://github.com/MLO-lab/MuVI" target="_blank" rel="noopener">MuVI&lt;/a>!&lt;/p></description></item></channel></rss>