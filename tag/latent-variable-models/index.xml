<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>latent variable models | MLO Lab</title><link>https://mlo-lab.github.io/tag/latent-variable-models/</link><atom:link href="https://mlo-lab.github.io/tag/latent-variable-models/index.xml" rel="self" type="application/rss+xml"/><description>latent variable models</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2025 MLO Lab</copyright><lastBuildDate>Tue, 22 Mar 2022 16:54:16 +0100</lastBuildDate><image><url>https://mlo-lab.github.io/media/logo_huedbb8239ffd36c55e33765ff7c80fb90_78702_300x300_fit_lanczos_2.png</url><title>latent variable models</title><link>https://mlo-lab.github.io/tag/latent-variable-models/</link></image><item><title>MuVI</title><link>https://mlo-lab.github.io/project/muvi/</link><pubDate>Tue, 22 Mar 2022 16:54:16 +0100</pubDate><guid>https://mlo-lab.github.io/project/muvi/</guid><description>&lt;p>Many real-world systems are described not only by data from a single source but via multiple data views. In genomic medicine, for instance, a patient can be described by data from different molecular layers. This raises the need for multi-view models that are able to disentangle variation within and across data views in an interpretable manner. Latent variable models with structured sparsity are a commonly used tool to address this modeling task but interpretability is cumbersome since it requires a direct inspection and interpretation of each factor via a specialized domain expert. Here, we propose MuVI, a novel approach for domain-informed multi-view latent variable models, facilitating the analysis of multi-view data in an inherently explainable manner. We demonstrate that our model (i) is able to integrate noisy domain expertise in from of feature sets, (ii) is robust to noise in the encoded domain knowledge, (iii) results in identifiable factors and (iv) is able to infer interpretable and biologically meaningful axes of variation in real-world multi-view datasets.&lt;/p>
&lt;p>Get started right away with &lt;a href="https://github.com/MLO-lab/MuVI" target="_blank" rel="noopener">MuVI&lt;/a>!&lt;/p></description></item><item><title>Probabilistic latent variable models</title><link>https://mlo-lab.github.io/project/lvmodels/</link><pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate><guid>https://mlo-lab.github.io/project/lvmodels/</guid><description>&lt;p>Latent variable models (LVMs) are a statistical tool to infer an unobserved, hidden state of a complex (e.g. biological) system based on observable data that is often high-dimensional. To this end, a high-dimensional dataset of correlated observations is reduced into a low-dimensional dataset of uncorrelated and interpretable latent variables. Probabilistic approaches allow for a principled way to disentangle distinct sources of variation and explicitly model dependencies between features as well as samples.&lt;/p>
&lt;h2 id="accounting-for-dependencies-between-genes-in-lvms">Accounting for dependencies between genes in LVMs&lt;/h2>
&lt;ul>
&lt;li>Standard latent variable models only model dependencies between samples&lt;/li>
&lt;li>Can we make dependencies between features (genes) explicit?&lt;/li>
&lt;li>Use framework of Gaussian Process Latent Variable Models (GP-LVM)&lt;/li>
&lt;li>Probabilistic kernel PCA via GP regression with unobserved input&lt;/li>
&lt;li>Introduce kernel to model covariance between genes&lt;/li>
&lt;li>Learn latent variables for genes and samples and connect via Kronecker Product&lt;/li>
&lt;li>Apply to matrix completion tasks&lt;/li>
&lt;/ul>
&lt;p>Reference: Yang &amp;amp; Buettner, UAI 2021 (in revision)&lt;/p>
&lt;h2 id="hierarchical-autoencoders-for-domain-generalisation">Hierarchical autoencoders for Domain Generalisation&lt;/h2>
&lt;ul>
&lt;li>Learn VAE to disentangle domain-specific information form class-specific information and residual variance&lt;/li>
&lt;li>Place Dirichlet prior on domain representation&lt;/li>
&lt;li>Learn “topics” that describe domain structure in unsupervised manner&lt;/li>
&lt;li>Interpretable model for unsupervised domain generalisation&lt;/li>
&lt;/ul>
&lt;p>Reference: Sun &amp;amp; Buettner, ICLR Workshop on robustML, 2021&lt;/p></description></item></channel></rss>